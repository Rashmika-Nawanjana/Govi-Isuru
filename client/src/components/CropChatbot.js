import React, { useState, useRef, useEffect } from 'react';
import axios from 'axios';
import { MessageCircle, Send, Bot, User, Leaf, HelpCircle, X, Minimize2, Maximize2, RotateCcw, ImagePlus, Loader2, AlertTriangle, Lightbulb, Mic, MicOff } from 'lucide-react';
const API_BASE = process.env.REACT_APP_API_URL || 'http://localhost:5000';
const AI_API = process.env.REACT_APP_AI_URL || 'http://localhost:8000';


// Follow-up suggestions based on intent
const followUpSuggestions = {
  en: {
    FERTILIZER: [
      "When should I apply it?",
      "What about organic alternatives?",
      "How much per hectare?",
      "Any side effects to watch for?"
    ],
    DISEASE: [
      "How to prevent this disease?",
      "What are early warning signs?",
      "Is it contagious to other crops?",
      "Organic treatment options?"
    ],
    DISEASE_DIAGNOSIS: [
      "How to prevent this disease?",
      "What causes this disease?",
      "Will it spread to other plants?",
      "Best time to apply treatment?"
    ],
    PEST: [
      "Natural pest control methods?",
      "How to identify early infestation?",
      "What attracts these pests?",
      "Prevention tips?"
    ],
    PLANTING: [
      "Best seed varieties?",
      "Soil preparation tips?",
      "Spacing recommendations?",
      "Water needs after planting?"
    ],
    HARVEST: [
      "Storage tips after harvest?",
      "How to check grain moisture?",
      "Best time of day to harvest?",
      "Post-harvest processing?"
    ],
    WATER: [
      "How to save water?",
      "Signs of overwatering?",
      "Drought management tips?",
      "Best irrigation method?"
    ],
    WEATHER: [
      "Crop protection from rain?",
      "Heat stress management?",
      "Flood prevention tips?",
      "When to delay field work?"
    ],
    SHADE: [
      "Best shade trees for tea?",
      "How much shade is ideal?",
      "When to reduce shade?",
      "Shade tree spacing?"
    ],
    PRUNING: [
      "When to prune tea bushes?",
      "What height for pruning?",
      "Recovery time after pruning?",
      "Tools for pruning?"
    ],
    CHILI: [
      "How to prevent chili diseases?",
      "Best fertilizer for chili?",
      "When to harvest chili?",
      "Pest control for chili?"
    ],
    GREETING: [
      "What fertilizer for rice?",
      "How to treat plant diseases?",
      "Tea plucking tips?",
      "Upload a plant photo üì∑"
    ],
    UNKNOWN: [
      "Tell me about rice farming",
      "Tea disease prevention?",
      "Fertilizer recommendations?",
      "Upload photo for diagnosis üì∑"
    ]
  },
  si: {
    FERTILIZER: [
      "‡∂ö‡∑Ä‡∂Ø‡∑è ‡∂∫‡∑ô‡∂Ø‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂Ø?",
      "‡∂¢‡∑õ‡∑Ä ‡∑Ä‡∑í‡∂ö‡∂Ω‡∑ä‡∂¥ ‡∂∏‡∑ú‡∂±‡∑Ä‡∑è‡∂Ø?",
      "‡∑Ñ‡∑ô‡∂ö‡∑ä‡∂ß‡∂∫‡∑è‡∂ª‡∂∫‡∂ö‡∂ß ‡∂ö‡∑ú‡∂¥‡∂∏‡∂´‡∂Ø?",
      "‡∂Ö‡∂≠‡∑î‡∂ª‡∑î ‡∂Ü‡∂∂‡∑è‡∂∞ ‡∂≠‡∑í‡∂∂‡∑ö‡∂Ø?"
    ],
    DISEASE: [
      "‡∂∏‡∑ô‡∂∏ ‡∂ª‡∑ù‡∂ú‡∂∫ ‡∑Ä‡∑ê‡∑Ö‡∑ê‡∂ö‡∑ä‡∑Ä‡∑ì‡∂∏‡∂ß ‡∂ö‡∑ô‡∑É‡∑ö‡∂Ø?",
      "‡∂∏‡∑î‡∂Ω‡∑ä ‡∂Ö‡∂±‡∂≠‡∑î‡∂ª‡∑î ‡∂á‡∂ü‡∑Ä‡∑ì‡∂∏‡∑ä ‡∂∏‡∑ú‡∂±‡∑Ä‡∑è‡∂Ø?",
      "‡∑Ä‡∑ô‡∂±‡∂≠‡∑ä ‡∂∂‡∑ù‡∂ú‡∑Ä‡∂Ω‡∂ß ‡∂¥‡∑ê‡∂≠‡∑í‡∂ª‡∑ö‡∂Ø?",
      "‡∂¢‡∑õ‡∑Ä ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂ö‡∑è‡∂ª ‡∑Ä‡∑í‡∂ö‡∂Ω‡∑ä‡∂¥?"
    ],
    DISEASE_DIAGNOSIS: [
      "‡∂∏‡∑ô‡∂∏ ‡∂ª‡∑ù‡∂ú‡∂∫ ‡∑Ä‡∑ê‡∑Ö‡∑ê‡∂ö‡∑ä‡∑Ä‡∑ì‡∂∏‡∂ß ‡∂ö‡∑ô‡∑É‡∑ö‡∂Ø?",
      "‡∂∏‡∑ô‡∂∏ ‡∂ª‡∑ù‡∂ú‡∂∫‡∂ß ‡∑Ñ‡∑ö‡∂≠‡∑î‡∑Ä ‡∂ö‡∑î‡∂∏‡∂ö‡∑ä‡∂Ø?",
      "‡∑Ä‡∑ô‡∂±‡∂≠‡∑ä ‡∑Å‡∑è‡∂ö‡∑Ä‡∂Ω‡∂ß ‡∂¥‡∑ê‡∂≠‡∑í‡∂ª‡∑ö‡∂Ø?",
      "‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂ö‡∑è‡∂ª ‡∂∫‡∑ô‡∂Ø‡∑ì‡∂∏‡∂ß ‡∑Ñ‡∑ú‡∂≥‡∂∏ ‡∂ö‡∑è‡∂Ω‡∂∫?"
    ],
    PEST: [
      "‡∑É‡∑ä‡∑Ä‡∑è‡∂∑‡∑è‡∑Ä‡∑í‡∂ö ‡∂¥‡∑Ö‡∑í‡∂∂‡∑ù‡∂∞ ‡∂¥‡∑è‡∂Ω‡∂±‡∂∫?",
      "‡∂∏‡∑î‡∂Ω‡∑ä ‡∂Ü‡∑É‡∑è‡∂Ø‡∂±‡∂∫ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è ‡∂ú‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑ô‡∑É‡∑ö‡∂Ø?",
      "‡∂∏‡∑ô‡∂∏ ‡∂¥‡∑Ö‡∑í‡∂∂‡∑ù‡∂∞‡∂∫‡∂±‡∑ä ‡∂Ü‡∂ö‡∂ª‡∑ä‡∑Ç‡∂´‡∂∫ ‡∑Ä‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑î‡∂∏‡∂ö‡∑í‡∂±‡∑ä‡∂Ø?",
      "‡∑Ä‡∑ê‡∑Ö‡∑ê‡∂ö‡∑ä‡∑Ä‡∑ì‡∂∏‡∑ö ‡∂â‡∂ü‡∑í?"
    ],
    PLANTING: [
      "‡∑Ñ‡∑ú‡∂≥‡∂∏ ‡∂∂‡∑ì‡∂¢ ‡∂¥‡∑ä‚Äç‡∂ª‡∂∑‡∑ö‡∂Ø?",
      "‡∂¥‡∑É ‡∑É‡∂ö‡∑É‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ö ‡∂â‡∂ü‡∑í?",
      "‡∂¥‡∂ª‡∂≠‡∂ª‡∂∫ ‡∂±‡∑í‡∂ª‡∑ä‡∂Ø‡∑ö‡∑Å?",
      "‡∑Ä‡∂ú‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ô‡∂±‡∑ä ‡∂¥‡∑É‡∑î ‡∂¢‡∂Ω ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫‡∂≠‡∑è?"
    ],
    HARVEST: [
      "‡∂Ö‡∑É‡∑ä‡∑Ä‡∂±‡∑î ‡∂±‡∑ô‡∂Ω‡∑ì‡∂∏‡∑ô‡∂±‡∑ä ‡∂¥‡∑É‡∑î ‡∂ú‡∂∂‡∂©‡∑è ‡∂â‡∂ü‡∑í?",
      "‡∂∞‡∑è‡∂±‡∑ä‚Äç‡∂∫ ‡∂≠‡∑ô‡∂≠‡∂∏‡∂±‡∂∫ ‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑ô‡∑É‡∑ö‡∂Ø?",
      "‡∂Ö‡∑É‡∑ä‡∑Ä‡∂±‡∑î ‡∂±‡∑ô‡∂Ω‡∑ì‡∂∏‡∂ß ‡∑Ñ‡∑ú‡∂≥‡∂∏ ‡∑Ä‡∑ö‡∂Ω‡∑è‡∑Ä?",
      "‡∂Ö‡∑É‡∑ä‡∑Ä‡∂±‡∑î ‡∂±‡∑ô‡∂Ω‡∑ì‡∂∏‡∑ô‡∂±‡∑ä ‡∂¥‡∑É‡∑î ‡∑É‡∑ê‡∂ö‡∑É‡∑ì‡∂∏?"
    ],
    WATER: [
      "‡∂¢‡∂Ω‡∂∫ ‡∂â‡∂≠‡∑í‡∂ª‡∑í ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑ô‡∑É‡∑ö‡∂Ø?",
      "‡∂Ö‡∂∞‡∑í‡∂ö ‡∂¢‡∂Ω‡∂∫ ‡∂∫‡∑ô‡∂Ø‡∑ì‡∂∏‡∑ö ‡∑É‡∂Ω‡∂ö‡∑î‡∂´‡∑î?",
      "‡∂±‡∑í‡∂∫‡∂Ç ‡∂ö‡∑Ö‡∂∏‡∂±‡∑è‡∂ö‡∂ª‡∂´ ‡∂â‡∂ü‡∑í?",
      "‡∑Ñ‡∑ú‡∂≥‡∂∏ ‡∑Ä‡∑è‡∂ª‡∑í‡∂∏‡∑è‡∂ª‡∑ä‡∂ú ‡∂ö‡∑ä‚Äç‡∂ª‡∂∏‡∂∫?"
    ],
    WEATHER: [
      "‡∑Ä‡∑ê‡∑É‡∑í ‡∑Ä‡∂Ω‡∑í‡∂±‡∑ä ‡∂∂‡∑ù‡∂ú ‡∂Ü‡∂ª‡∂ö‡∑ä‡∑Ç‡∑è‡∑Ä?",
      "‡∂≠‡∑è‡∂¥ ‡∂Ü‡∂≠‡∂≠‡∑í‡∂∫ ‡∂ö‡∑Ö‡∂∏‡∂±‡∑è‡∂ö‡∂ª‡∂´‡∂∫?",
      "‡∂ú‡∂Ç‡∑Ä‡∂≠‡∑î‡∂ª ‡∑Ä‡∑ê‡∑Ö‡∑ê‡∂ö‡∑ä‡∑Ä‡∑ì‡∂∏‡∑ö ‡∂â‡∂ü‡∑í?",
      "‡∂ö‡∑ô‡∂≠‡∑ä ‡∑Ä‡∑ê‡∂© ‡∂¥‡∑ä‚Äç‡∂ª‡∂∏‡∑è‡∂Ø ‡∂ö‡∑Ö ‡∂∫‡∑î‡∂≠‡∑ä‡∂≠‡∑ö ‡∂ö‡∑Ä‡∂Ø‡∑è‡∂Ø?"
    ],
    SHADE: [
      "‡∂≠‡∑ö ‡∑É‡∂≥‡∑Ñ‡∑è ‡∑Ñ‡∑ú‡∂≥‡∂∏ ‡∑É‡∑ô‡∑Ä‡∂± ‡∂ú‡∑É‡∑ä?",
      "‡∂ö‡∑ú‡∂¥‡∂∏‡∂´ ‡∑É‡∑ô‡∑Ä‡∂±‡∂ö‡∑ä ‡∑É‡∑î‡∂Ø‡∑î‡∑É‡∑î‡∂Ø?",
      "‡∑É‡∑ô‡∑Ä‡∂± ‡∂Ö‡∂©‡∑î ‡∂ö‡∑Ö ‡∂∫‡∑î‡∂≠‡∑ä‡∂≠‡∑ö ‡∂ö‡∑Ä‡∂Ø‡∑è‡∂Ø?",
      "‡∑É‡∑ô‡∑Ä‡∂± ‡∂ú‡∑É‡∑ä ‡∂¥‡∂ª‡∂≠‡∂ª‡∂∫?"
    ],
    PRUNING: [
      "‡∂≠‡∑ö ‡∂¥‡∂≥‡∑î‡∂ª‡∑î ‡∂ö‡∂¥‡∑ä‡∂¥‡∑è‡∂Ø‡∑î ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑Ä‡∂Ø‡∑è‡∂Ø?",
      "‡∂ö‡∂¥‡∑ä‡∂¥‡∑è‡∂Ø‡∑î ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂ã‡∑É ‡∂ö‡∑ú‡∂¥‡∂∏‡∂´‡∂Ø?",
      "‡∂ö‡∂¥‡∑ä‡∂¥‡∑è‡∂Ø‡∑î ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∑ô‡∂±‡∑ä ‡∂¥‡∑É‡∑î ‡∂∫‡∂Æ‡∑è ‡∂ö‡∑è‡∂Ω‡∂∫?",
      "‡∂ö‡∂¥‡∑ä‡∂¥‡∑è‡∂Ø‡∑î ‡∂∏‡∑ô‡∑Ä‡∂Ω‡∂∏‡∑ä?"
    ],    CHILI: [
      "‡∂∏‡∑í‡∂ª‡∑í‡∑É‡∑ä ‡∂ª‡∑ù‡∂ú ‡∑Ä‡∑ê‡∑Ö‡∑ê‡∂ö‡∑ä‡∑Ä‡∑ì‡∂∏‡∂ß ‡∂ö‡∑ô‡∑É‡∑ö‡∂Ø?",
      "‡∂∏‡∑í‡∂ª‡∑í‡∑É‡∑ä ‡∑É‡∂≥‡∑Ñ‡∑è ‡∑Ñ‡∑ú‡∂≥‡∂∏ ‡∂¥‡∑ú‡∑Ñ‡∑ú‡∂ª?",
      "‡∂∏‡∑í‡∂ª‡∑í‡∑É‡∑ä ‡∂Ö‡∑É‡∑ä‡∑Ä‡∑ê‡∂±‡∑î ‡∂±‡∑ô‡∂Ω‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑Ä‡∂Ø‡∑è‡∂Ø?",
      "‡∂∏‡∑í‡∂ª‡∑í‡∑É‡∑ä ‡∂¥‡∑Ö‡∑í‡∂∂‡∑ù‡∂∞ ‡∂¥‡∑è‡∂Ω‡∂±‡∂∫?"
    ],    GREETING: [
      "‡∑Ä‡∑ì ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂¥‡∑ú‡∑Ñ‡∑ú‡∂ª ‡∂ö‡∑î‡∂∏‡∂ö‡∑ä‡∂Ø?",
      "‡∑Å‡∑è‡∂ö ‡∂ª‡∑ù‡∂ú ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂ö‡∑è‡∂ª ‡∂ö‡∂ª‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑ô‡∑É‡∑ö‡∂Ø?",
      "‡∂≠‡∑ö ‡∂±‡∑ô‡∂Ω‡∑ì‡∂∏‡∑ö ‡∂â‡∂ü‡∑í?",
      "‡∑Å‡∑è‡∂ö ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫‡∂ö‡∑ä ‡∂ã‡∂©‡∑î‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂±‡∑ä‡∂± üì∑"
    ],
    UNKNOWN: [
      "‡∑Ä‡∑ì ‡∑Ä‡∂ú‡∑è‡∑Ä ‡∂ú‡∑ê‡∂± ‡∂ö‡∑í‡∂∫‡∂±‡∑ä‡∂±",
      "‡∂≠‡∑ö ‡∂ª‡∑ù‡∂ú ‡∑Ä‡∑ê‡∑Ö‡∑ê‡∂ö‡∑ä‡∑Ä‡∑ì‡∂∏?",
      "‡∂¥‡∑ú‡∑Ñ‡∑ú‡∂ª ‡∂±‡∑í‡∂ª‡∑ä‡∂Ø‡∑ö‡∑Å?",
      "‡∂ª‡∑ù‡∂ú ‡∑Ä‡∑í‡∂±‡∑í‡∑Å‡∑ä‡∂†‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫‡∂ö‡∑ä üì∑"
    ]
  }
};

const translations = {
  en: {
    title: "Crop Assistant",
    subtitle: "Ask me about farming!",
    placeholder: "Ask about rice, tea, chili, fertilizer, diseases...",
    send: "Send",
    typing: "Thinking...",
    source: "Source",
    suggestions: [
      "What fertilizer for rice in Yala?",
      "How to treat tea blister blight?",
      "When to harvest rice?",
      "Tea pruning advice"
    ],
    welcome: "üëã Hello! I'm your Govi Isuru farming assistant. Ask me about rice, tea, or chili - fertilizers, diseases, planting, or harvesting! You can also upload plant photos for disease diagnosis.",
    uploadImage: "Upload plant photo",
    analyzing: "Analyzing image...",
    diagnosisResult: "Disease Diagnosis",
    confidence: "Confidence",
    treatment: "Treatment",
    showHeatmap: "Show AI Focus",
    hideHeatmap: "Hide AI Focus",
    voiceListening: "Listening...",
    voiceNotSupported: "Voice input not supported in this browser",
    voiceError: "Could not recognize speech. Please try again.",
    tapToSpeak: "Tap to speak"
  },
  si: {
    title: "‡∂∂‡∑ù‡∂ú ‡∑É‡∑Ñ‡∑è‡∂∫‡∂ö",
    subtitle: "‡∂ú‡∑ú‡∑Ä‡∑í‡∂≠‡∑ê‡∂±‡∑ä ‡∂ú‡∑ê‡∂± ‡∂∏‡∂ú‡∑ô‡∂±‡∑ä ‡∂Ö‡∑Ñ‡∂±‡∑ä‡∂±!",
    placeholder: "‡∑Ä‡∑ì, ‡∂≠‡∑ö, ‡∂∏‡∑í‡∂ª‡∑í‡∑É‡∑ä, ‡∂¥‡∑ú‡∑Ñ‡∑ú‡∂ª, ‡∂ª‡∑ù‡∂ú ‡∂ú‡∑ê‡∂± ‡∂Ö‡∑Ñ‡∂±‡∑ä‡∂±...",
    send: "‡∂∫‡∑Ä‡∂±‡∑ä‡∂±",
    typing: "‡∑É‡∑í‡∂≠‡∂∏‡∑í‡∂±‡∑ä...",
    source: "‡∂∏‡∑ñ‡∂Ω‡∑è‡∑Å‡∑ä‚Äç‡∂ª‡∂∫",
    suggestions: [
      "‡∂∫‡∑è‡∂Ω ‡∂ö‡∂±‡∑ä‡∂±‡∂∫‡∑ö ‡∑Ä‡∑ì ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂¥‡∑ú‡∑Ñ‡∑ú‡∂ª?",
      "‡∂≠‡∑ö ‡∂∂‡∑í‡∂∂‡∑í‡∂Ω‡∑í ‡∂ª‡∑ù‡∂ú‡∂∫‡∂ß ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂ö‡∑è‡∂ª?",
      "‡∑Ä‡∑ì ‡∂Ö‡∑É‡∑ä‡∑Ä‡∂±‡∑î ‡∂±‡∑ô‡∂Ω‡∂±‡∑ä‡∂±‡∑ö ‡∂ö‡∑Ä‡∂Ø‡∑è‡∂Ø?",
      "‡∂≠‡∑ö ‡∂ö‡∂¥‡∑ä‡∂¥‡∑è‡∂Ø‡∑î ‡∂ã‡∂¥‡∂Ø‡∑ô‡∑É‡∑ä"
    ],
    welcome: "üëã ‡∂Ü‡∂∫‡∑î‡∂∂‡∑ù‡∑Ä‡∂±‡∑ä! ‡∂∏‡∂∏ ‡∂î‡∂∂‡∑ö ‡∂ú‡∑ú‡∑Ä‡∑í ‡∂â‡∑É‡∑î‡∂ª‡∑î ‡∂ú‡∑ú‡∑Ä‡∑í‡∂≠‡∑ê‡∂±‡∑ä ‡∑É‡∑Ñ‡∑è‡∂∫‡∂ö‡∂∫‡∑è. ‡∑Ä‡∑ì, ‡∂≠‡∑ö ‡∑Ñ‡∑ù ‡∂∏‡∑í‡∂ª‡∑í‡∑É‡∑ä ‡∂ú‡∑ê‡∂± - ‡∂¥‡∑ú‡∑Ñ‡∑ú‡∂ª, ‡∂ª‡∑ù‡∂ú, ‡∑Ä‡∂ú‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∑Ñ‡∑ù ‡∂Ö‡∑É‡∑ä‡∑Ä‡∑ê‡∂±‡∑î ‡∂±‡∑ô‡∂Ω‡∑ì‡∂∏ ‡∂ú‡∑ê‡∂± ‡∂∏‡∂ú‡∑ô‡∂±‡∑ä ‡∂Ö‡∑Ñ‡∂±‡∑ä‡∂±! ‡∂ª‡∑ù‡∂ú ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∑Å‡∑è‡∂ö ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥ ‡∂â‡∂©‡∑î‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.",
    uploadImage: "‡∑Å‡∑è‡∂ö ‡∂°‡∑è‡∂∫‡∑è‡∂ª‡∑ñ‡∂¥‡∂∫ ‡∂ã‡∂©‡∑î‡∂ú‡∂≠ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±",
    analyzing: "‡∂ª‡∑ñ‡∂¥‡∂∫ ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫ ‡∂ö‡∂ª‡∂∏‡∑í‡∂±‡∑ä...",
    diagnosisResult: "‡∂ª‡∑ù‡∂ú ‡∑Ä‡∑í‡∂±‡∑í‡∑Å‡∑ä‡∂†‡∂∫",
    confidence: "‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä‡∑è‡∑É‡∂∫",
    treatment: "‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∂ö‡∑è‡∂ª",
    showHeatmap: "AI ‡∂Ö‡∑Ä‡∂∞‡∑è‡∂±‡∂∫ ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∂±‡∑ä‡∂±",
    hideHeatmap: "AI ‡∂Ö‡∑Ä‡∂∞‡∑è‡∂±‡∂∫ ‡∑É‡∂ü‡∑Ä‡∂±‡∑ä‡∂±",
    voiceListening: "‡∑É‡∑Ä‡∂±‡∑ä ‡∂Ø‡∑ô‡∂∏‡∑í‡∂±‡∑ä...",
    voiceNotSupported: "‡∂∏‡∑ô‡∂∏ ‡∂∂‡∑ä‚Äç‡∂ª‡∑Ä‡∑î‡∑É‡∂ª‡∂∫‡∑ö ‡∑Ñ‡∂¨ ‡∂Ü‡∂Ø‡∑è‡∂±‡∂∫ ‡∑É‡∑Ñ‡∑è‡∂∫ ‡∂±‡∑ú‡∂Ø‡∂ö‡∑ä‡∑Ä‡∂∫‡∑í",
    voiceError: "‡∂ö‡∂Æ‡∂±‡∂∫ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è ‡∂ú‡∂≠ ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑Ä‡∑í‡∂∫. ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂±‡∑ê‡∑Ä‡∂≠ ‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.",
    tapToSpeak: "‡∂ö‡∂≠‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß ‡∂≠‡∂ß‡∑ä‡∂ß‡∑î ‡∂ö‡∂ª‡∂±‡∑ä‡∂±"
  }
};

// Component for displaying diagnosis images with Grad-CAM toggle
function DiagnosisImages({ originalImage, gradcamImage, disease, confidence, lang, t }) {
  const [showGradcam, setShowGradcam] = useState(false);
  
  return (
    <div className="mt-3 space-y-2">
      {/* Image comparison */}
      <div className="relative rounded-lg overflow-hidden bg-slate-100">
        <img 
          src={showGradcam ? gradcamImage : originalImage}
          alt={showGradcam ? "AI Analysis Heatmap" : "Original plant image"}
          className="w-full max-h-48 object-contain"
        />
        
        {/* Confidence badge */}
        <div className={`absolute top-2 right-2 px-2 py-1 rounded-full text-xs font-bold ${
          parseFloat(confidence) >= 70 ? 'bg-green-500 text-white' :
          parseFloat(confidence) >= 50 ? 'bg-yellow-500 text-white' :
          'bg-red-500 text-white'
        }`}>
          {confidence}%
        </div>
        
        {/* Grad-CAM indicator */}
        {showGradcam && (
          <div className="absolute top-2 left-2 px-2 py-1 bg-purple-600 text-white rounded-full text-xs font-bold flex items-center gap-1">
            <span className="w-2 h-2 bg-red-400 rounded-full"></span>
            AI Focus
          </div>
        )}
      </div>
      
      {/* Toggle button */}
      <button
        onClick={() => setShowGradcam(!showGradcam)}
        className={`w-full text-xs py-2 px-3 rounded-lg transition-colors flex items-center justify-center gap-2 ${
          showGradcam 
            ? 'bg-purple-100 text-purple-700 hover:bg-purple-200' 
            : 'bg-slate-100 text-slate-600 hover:bg-slate-200'
        }`}
      >
        {showGradcam ? (
          <>
            <span className="w-2 h-2 bg-purple-500 rounded-full"></span>
            {t.hideHeatmap}
          </>
        ) : (
          <>
            <span className="w-2 h-2 bg-slate-400 rounded-full"></span>
            {t.showHeatmap}
          </>
        )}
      </button>
    </div>
  );
}

// Component for smart follow-up suggestions based on last bot response
function FollowUpSuggestions({ messages, lang, t, onSuggestionClick, isLoading }) {
  // Get last bot message to determine context
  const lastBotMessage = [...messages].reverse().find(msg => msg.type === 'bot' && msg.intent);
  const lastIntent = lastBotMessage?.intent || 'GREETING';
  
  // Get appropriate suggestions based on intent
  const suggestions = followUpSuggestions[lang]?.[lastIntent] || 
                      followUpSuggestions[lang]?.UNKNOWN ||
                      followUpSuggestions.en.UNKNOWN;
  
  // For initial state, use default suggestions
  const isInitial = messages.length <= 2;
  const displaySuggestions = isInitial ? t.suggestions : suggestions;
  
  if (isLoading) return null;
  
  return (
    <div className="px-4 pb-2 bg-slate-50">
      {/* Header for follow-up suggestions */}
      {!isInitial && (
        <div className="flex items-center gap-1 mb-2 text-xs text-slate-500">
          <Lightbulb size={12} className="text-yellow-500" />
          <span>{lang === 'si' ? '‡∂∫‡∑ù‡∂¢‡∑í‡∂≠ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±:' : 'Suggested questions:'}</span>
        </div>
      )}
      
      <div className="flex flex-wrap gap-2">
        {displaySuggestions.slice(0, 4).map((suggestion, idx) => (
          <button
            key={idx}
            onClick={() => onSuggestionClick(suggestion)}
            className="text-xs bg-green-50 text-green-700 px-3 py-1.5 rounded-full hover:bg-green-100 transition-colors border border-green-200 hover:border-green-300"
          >
            {suggestion}
          </button>
        ))}
      </div>
    </div>
  );
}

export default function CropChatbot({ lang = 'en' }) {
  const [isOpen, setIsOpen] = useState(false);
  const [isMinimized, setIsMinimized] = useState(false);
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [currentContext, setCurrentContext] = useState({ crop: null, season: null });
  const [isAnalyzingImage, setIsAnalyzingImage] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [speechSupported, setSpeechSupported] = useState(true);
  const [selectedCropType, setSelectedCropType] = useState('rice'); // New: crop type for image analysis
  const messagesEndRef = useRef(null);
  const fileInputRef = useRef(null);
  const recognitionRef = useRef(null);
  const t = translations[lang] || translations.en;

  // Initialize speech recognition
  useEffect(() => {
    // Check for browser support
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      setSpeechSupported(false);
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.continuous = false;
    recognition.interimResults = true;
    
    // Set language based on app language
    recognition.lang = lang === 'si' ? 'si-LK' : 'en-US';

    recognition.onstart = () => {
      setIsListening(true);
    };

    recognition.onresult = (event) => {
      const transcript = Array.from(event.results)
        .map(result => result[0].transcript)
        .join('');
      
      setInput(transcript);
      
      // If final result, send the message
      if (event.results[0].isFinal) {
        setIsListening(false);
      }
    };

    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      setIsListening(false);
      
      if (event.error === 'not-allowed') {
        alert(lang === 'si' 
          ? '‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂∏‡∂∫‡∑í‡∂ö‡∑ä‚Äç‡∂ª‡∑ú‡∑Ü‡∑ù‡∂±‡∑ä ‡∂¥‡∑ä‚Äç‡∂ª‡∑Ä‡∑ö‡∑Å‡∂∫‡∂ß ‡∂Ö‡∑Ä‡∑É‡∂ª ‡∂Ø‡∑ô‡∂±‡∑ä‡∂±' 
          : 'Please allow microphone access');
      }
    };

    recognition.onend = () => {
      setIsListening(false);
    };

    recognitionRef.current = recognition;

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
    };
  }, [lang]);

  // Update recognition language when app language changes
  useEffect(() => {
    if (recognitionRef.current) {
      recognitionRef.current.lang = lang === 'si' ? 'si-LK' : 'en-US';
    }
  }, [lang]);

  // Initialize with welcome message
  useEffect(() => {
    if (messages.length === 0) {
      setMessages([{
        id: 1,
        type: 'bot',
        text: t.welcome,
        timestamp: new Date()
      }]);
    }
  }, [lang]);

  // Auto-scroll to bottom
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  const sendMessage = async (text = input) => {
    if (!text.trim()) return;

    const userMessage = {
      id: Date.now(),
      type: 'user',
      text: text.trim(),
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setIsLoading(true);

    try {
      // Build conversation history for context
      const history = messages
        .filter(msg => msg.type === 'user' || msg.type === 'bot')
        .map(msg => ({
          role: msg.type === 'user' ? 'user' : 'assistant',
          content: msg.text,
          intent: msg.intent || null
        }));
      
      // Add current message to history
      history.push({ role: 'user', content: text.trim() });

      const response = await axios.post(`${API_BASE}/chatbot/chat`, {
        message: text.trim(),
        language: lang,
        history: history.slice(-10) // Send last 10 messages for context
      });

      const botMessage = {
        id: Date.now() + 1,
        type: 'bot',
        text: response.data.answer,
        source: response.data.source,
        intent: response.data.intent,
        context: response.data.context, // Store context for reference
        timestamp: new Date()
      };

      // Update current context if detected
      if (response.data.context) {
        setCurrentContext(prev => ({
          crop: response.data.context.crop || prev.crop,
          season: response.data.context.season || prev.season
        }));
      }

      setMessages(prev => [...prev, botMessage]);
    } catch (error) {
      console.error('Chatbot error:', error);
      const errorMessage = {
        id: Date.now() + 1,
        type: 'bot',
        text: lang === 'si' 
          ? '‡∑É‡∂∏‡∑è‡∑Ä‡∑ô‡∂±‡∑ä‡∂±, ‡∂Ø‡∑ù‡∑Ç‡∂∫‡∂ö‡∑ä ‡∂á‡∂≠‡∑í ‡∑Ä‡∑í‡∂∫. ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂±‡∑ê‡∑Ä‡∂≠ ‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.'
          : 'Sorry, something went wrong. Please try again.',
        timestamp: new Date()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleKeyPress = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  };

  const handleSuggestionClick = (suggestion) => {
    sendMessage(suggestion);
  };

  // Toggle voice input
  const toggleVoiceInput = () => {
    if (!speechSupported) {
      alert(t.voiceNotSupported);
      return;
    }

    if (isListening) {
      recognitionRef.current?.stop();
      setIsListening(false);
    } else {
      try {
        recognitionRef.current?.start();
      } catch (error) {
        console.error('Speech recognition start error:', error);
        // Recognition might already be running
        recognitionRef.current?.stop();
        setTimeout(() => {
          recognitionRef.current?.start();
        }, 100);
      }
    }
  };

  // Clear chat and reset context
  const clearChat = () => {
    setMessages([{
      id: Date.now(),
      type: 'bot',
      text: t.welcome,
      timestamp: new Date()
    }]);
    setCurrentContext({ crop: null, season: null });
  };

  // Handle image upload for disease diagnosis
  const handleImageUpload = async (event) => {
    const file = event.target.files[0];
    if (!file) return;

    // Validate file type
    if (!file.type.startsWith('image/')) {
      alert(lang === 'si' ? '‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª ‡∂ª‡∑ñ‡∂¥‡∂∫‡∂ö‡∑ä ‡∂≠‡∑ù‡∂ª‡∂±‡∑ä‡∂±' : 'Please select an image file');
      return;
    }

    // Create preview URL
    const imageUrl = URL.createObjectURL(file);

    // Add user message with image
    const userMessage = {
      id: Date.now(),
      type: 'user',
      text: lang === 'si' 
        ? `üîç ‡∂∏‡∑ô‡∂∏ ${selectedCropType === 'tea' ? '‡∂≠‡∑ö' : selectedCropType === 'chili' ? '‡∂∏‡∑í‡∂ª‡∑í‡∑É‡∑ä' : '‡∑Ä‡∑ì'} ‡∑Å‡∑è‡∂ö‡∂∫‡∑ö ‡∂ª‡∑ù‡∂ú‡∂∫ ‡∑Ñ‡∂≥‡∑î‡∂±‡∑è ‡∂ú‡∂±‡∑ä‡∂±` 
        : `üîç Diagnose this ${selectedCropType} plant`,
      image: imageUrl,
      timestamp: new Date()
    };
    setMessages(prev => [...prev, userMessage]);
    setIsAnalyzingImage(true);

    try {
      // Send image to AI service with crop type
      const formData = new FormData();
      formData.append('file', file);

      const response = await axios.post(`${API_BASE}/ai/predict/${selectedCropType}`, formData, {
        headers: { 'Content-Type': 'multipart/form-data' }
      });

      const { prediction, confidence, treatment, gradcam } = response.data;
      
      // Get treatment text - can be array or string
      const treatmentText = Array.isArray(treatment) 
        ? treatment.join('\n‚Ä¢ ') 
        : (treatment || 'No treatment information available');
      
      // Format confidence percentage
      const confidencePercent = (confidence * 100).toFixed(1);
      
      // Build diagnosis message
      const diagnosisText = lang === 'si' 
        ? `üî¨ **${t.diagnosisResult}**\n\nü¶† **‡∂ª‡∑ù‡∂ú‡∂∫:** ${prediction}\nüìä **${t.confidence}:** ${confidencePercent}%\n\nüíä **${t.treatment}:**\n‚Ä¢ ${treatmentText}`
        : `üî¨ **${t.diagnosisResult}**\n\nü¶† **Disease:** ${prediction}\nüìä **${t.confidence}:** ${confidencePercent}%\n\nüíä **${t.treatment}:**\n‚Ä¢ ${treatmentText}`;

      // Get gradcam overlay image (with data URL prefix)
      const gradcamOverlay = gradcam?.overlay 
        ? `data:image/png;base64,${gradcam.overlay}` 
        : null;

      const botMessage = {
        id: Date.now() + 1,
        type: 'bot',
        text: diagnosisText,
        source: 'AI Crop Doctor (MobileNetV2 + Grad-CAM)',
        intent: 'DISEASE_DIAGNOSIS',
        gradcam: gradcamOverlay, // Store Grad-CAM overlay image
        originalImage: imageUrl,
        disease: prediction,
        confidence: confidencePercent,
        timestamp: new Date()
      };

      // Update context with detected disease
      setCurrentContext(prev => ({
        ...prev,
        crop: selectedCropType,
        disease: prediction
      }));

      setMessages(prev => [...prev, botMessage]);
    } catch (error) {
      console.error('Image analysis error:', error);
      const errorMessage = {
        id: Date.now() + 1,
        type: 'bot',
        text: lang === 'si' 
          ? '‚ùå ‡∂ª‡∑ñ‡∂¥‡∂∫ ‡∑Ä‡∑í‡∑Å‡∑ä‡∂Ω‡∑ö‡∑Ç‡∂´‡∂∫ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ß ‡∂±‡∑ú‡∑Ñ‡∑ê‡∂ö‡∑í ‡∑Ä‡∑í‡∂∫. AI ‡∑É‡∑ö‡∑Ä‡∑è‡∑Ä ‡∂ö‡∑ä‚Äç‡∂ª‡∑í‡∂∫‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∂Ø‡∑ê‡∂∫‡∑í ‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.'
          : '‚ùå Could not analyze the image. Please make sure the AI service is running on port 8000.',
        timestamp: new Date()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsAnalyzingImage(false);
      // Reset file input
      if (fileInputRef.current) {
        fileInputRef.current.value = '';
      }
    }
  };

  // Floating chat button
  if (!isOpen) {
    return (
      <button
        onClick={() => setIsOpen(true)}
        className="fixed bottom-6 right-6 bg-green-600 hover:bg-green-700 text-white p-4 rounded-full shadow-2xl transition-all hover:scale-110 z-50 flex items-center gap-2"
        title={t.title}
      >
        <MessageCircle size={24} />
        <span className="hidden md:inline font-bold">{t.title}</span>
      </button>
    );
  }

  // Minimized state
  if (isMinimized) {
    return (
      <div className="fixed bottom-6 right-6 bg-green-600 text-white rounded-2xl shadow-2xl z-50 flex items-center gap-3 px-4 py-3 cursor-pointer hover:bg-green-700"
           onClick={() => setIsMinimized(false)}>
        <Bot size={20} />
        <span className="font-bold">{t.title}</span>
        <Maximize2 size={16} />
      </div>
    );
  }

  // Full chat window
  return (
    <div className="fixed bottom-6 right-6 w-96 max-w-[calc(100vw-3rem)] bg-white rounded-2xl shadow-2xl z-50 flex flex-col overflow-hidden border border-slate-200"
         style={{ height: '500px', maxHeight: 'calc(100vh - 6rem)' }}>
      
      {/* Header */}
      <div className="bg-gradient-to-r from-green-600 to-green-700 text-white p-4 flex items-center justify-between">
        <div className="flex items-center gap-3">
          <div className="bg-white/20 p-2 rounded-full">
            <Leaf size={20} />
          </div>
          <div>
            <h3 className="font-bold text-lg">{t.title}</h3>
            <div className="flex items-center gap-2">
              <p className="text-xs text-green-100">{t.subtitle}</p>
              {/* Context indicator */}
              {(currentContext.crop || currentContext.season) && (
                <div className="flex gap-1">
                  {currentContext.crop && (
                    <span className="text-[10px] bg-white/20 px-2 py-0.5 rounded-full">
                      üåæ {currentContext.crop}
                    </span>
                  )}
                  {currentContext.season && (
                    <span className="text-[10px] bg-white/20 px-2 py-0.5 rounded-full">
                      üìÖ {currentContext.season}
                    </span>
                  )}
                </div>
              )}
            </div>
          </div>
        </div>
        <div className="flex items-center gap-2">
          <button 
            onClick={clearChat} 
            className="hover:bg-white/20 p-2 rounded-lg transition-colors"
            title={lang === 'si' ? '‡∂±‡∑Ä ‡∑É‡∂Ç‡∑Ä‡∑è‡∂Ø‡∂∫' : 'New chat'}
          >
            <RotateCcw size={18} />
          </button>
          <button onClick={() => setIsMinimized(true)} className="hover:bg-white/20 p-2 rounded-lg transition-colors">
            <Minimize2 size={18} />
          </button>
          <button onClick={() => setIsOpen(false)} className="hover:bg-white/20 p-2 rounded-lg transition-colors">
            <X size={18} />
          </button>
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4 bg-slate-50">
        {messages.map((msg) => (
          <div key={msg.id} className={`flex ${msg.type === 'user' ? 'justify-end' : 'justify-start'}`}>
            <div className={`flex gap-2 max-w-[85%] ${msg.type === 'user' ? 'flex-row-reverse' : ''}`}>
              {/* Avatar */}
              <div className={`flex-shrink-0 w-8 h-8 rounded-full flex items-center justify-center ${
                msg.type === 'user' ? 'bg-green-600 text-white' : 'bg-green-100 text-green-700'
              }`}>
                {msg.type === 'user' ? <User size={16} /> : <Bot size={16} />}
              </div>
              
              {/* Message bubble */}
              <div className={`rounded-2xl px-4 py-3 ${
                msg.type === 'user' 
                  ? 'bg-green-600 text-white rounded-br-md' 
                  : 'bg-white text-slate-700 rounded-bl-md shadow-sm border border-slate-100'
              }`}>
                {/* User uploaded image */}
                {msg.image && msg.type === 'user' && (
                  <img 
                    src={msg.image} 
                    alt="Uploaded plant" 
                    className="rounded-lg mb-2 max-w-full max-h-40 object-cover"
                  />
                )}
                
                <p className="text-sm leading-relaxed whitespace-pre-wrap">{msg.text}</p>
                
                {/* Grad-CAM visualization for diagnosis */}
                {msg.gradcam && (
                  <DiagnosisImages 
                    originalImage={msg.originalImage}
                    gradcamImage={msg.gradcam}
                    disease={msg.disease}
                    confidence={msg.confidence}
                    lang={lang}
                    t={t}
                  />
                )}
                
                {msg.source && (
                  <p className={`text-xs mt-2 pt-2 border-t ${
                    msg.type === 'user' ? 'border-green-500 text-green-100' : 'border-slate-100 text-slate-400'
                  }`}>
                    üìö {t.source}: {msg.source}
                  </p>
                )}
              </div>
            </div>
          </div>
        ))}
        
        {/* Image analyzing indicator */}
        {isAnalyzingImage && (
          <div className="flex justify-start">
            <div className="flex gap-2">
              <div className="w-8 h-8 rounded-full bg-green-100 text-green-700 flex items-center justify-center">
                <Bot size={16} />
              </div>
              <div className="bg-white rounded-2xl rounded-bl-md px-4 py-3 shadow-sm border border-slate-100">
                <div className="flex items-center gap-2 text-slate-600">
                  <Loader2 size={16} className="animate-spin text-green-600" />
                  <span className="text-sm">{t.analyzing}</span>
                </div>
              </div>
            </div>
          </div>
        )}
        
        {/* Loading indicator */}
        {isLoading && (
          <div className="flex justify-start">
            <div className="flex gap-2">
              <div className="w-8 h-8 rounded-full bg-green-100 text-green-700 flex items-center justify-center">
                <Bot size={16} />
              </div>
              <div className="bg-white rounded-2xl rounded-bl-md px-4 py-3 shadow-sm border border-slate-100">
                <div className="flex items-center gap-2 text-slate-400">
                  <div className="flex gap-1">
                    <span className="w-2 h-2 bg-green-400 rounded-full animate-bounce" style={{ animationDelay: '0ms' }}></span>
                    <span className="w-2 h-2 bg-green-400 rounded-full animate-bounce" style={{ animationDelay: '150ms' }}></span>
                    <span className="w-2 h-2 bg-green-400 rounded-full animate-bounce" style={{ animationDelay: '300ms' }}></span>
                  </div>
                  <span className="text-xs">{t.typing}</span>
                </div>
              </div>
            </div>
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      {/* Smart Follow-up Suggestions */}
      <FollowUpSuggestions 
        messages={messages}
        lang={lang}
        t={t}
        onSuggestionClick={handleSuggestionClick}
        isLoading={isLoading || isAnalyzingImage}
      />

      {/* Input */}
      <div className="p-4 bg-white border-t border-slate-100">
        {/* Crop type selector for image analysis */}
        <div className="flex items-center gap-2 mb-3">
          <span className="text-xs text-slate-500">
            {lang === 'si' ? '‡∂ª‡∑ù‡∂ú ‡∑Ä‡∑í‡∂±‡∑í‡∑Å‡∑ä‡∂†‡∂∫ ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂∂‡∑ù‡∂ú‡∂∫:' : 'Crop for diagnosis:'}
          </span>
          <div className="flex gap-1">
            <button
              onClick={() => setSelectedCropType('rice')}
              className={`px-3 py-1 rounded-full text-xs font-medium transition-all ${
                selectedCropType === 'rice'
                  ? 'bg-green-600 text-white'
                  : 'bg-slate-100 text-slate-600 hover:bg-slate-200'
              }`}
            >
              üåæ {lang === 'si' ? '‡∑Ä‡∑ì' : 'Rice'}
            </button>
            <button
              onClick={() => setSelectedCropType('tea')}
              className={`px-3 py-1 rounded-full text-xs font-medium transition-all ${
                selectedCropType === 'tea'
                  ? 'bg-green-600 text-white'
                  : 'bg-slate-100 text-slate-600 hover:bg-slate-200'
              }`}
            >
              üçÉ {lang === 'si' ? '‡∂≠‡∑ö' : 'Tea'}
            </button>
            <button
              onClick={() => setSelectedCropType('chili')}
              className={`px-3 py-1 rounded-full text-xs font-medium transition-all ${
                selectedCropType === 'chili'
                  ? 'bg-red-600 text-white'
                  : 'bg-slate-100 text-slate-600 hover:bg-slate-200'
              }`}
            >
              üå∂Ô∏è {lang === 'si' ? '‡∂∏‡∑í‡∂ª‡∑í‡∑É‡∑ä' : 'Chili'}
            </button>
          </div>
        </div>

        {/* Voice listening indicator */}
        {isListening && (
          <div className="flex items-center justify-center gap-2 mb-3 py-2 bg-red-50 rounded-lg border border-red-200">
            <div className="relative">
              <Mic size={18} className="text-red-500" />
              <span className="absolute -top-1 -right-1 w-2 h-2 bg-red-500 rounded-full animate-ping"></span>
            </div>
            <span className="text-sm text-red-600 font-medium">{t.voiceListening}</span>
            <div className="flex gap-1">
              <span className="w-1 h-3 bg-red-400 rounded-full animate-pulse"></span>
              <span className="w-1 h-4 bg-red-500 rounded-full animate-pulse" style={{ animationDelay: '150ms' }}></span>
              <span className="w-1 h-2 bg-red-400 rounded-full animate-pulse" style={{ animationDelay: '300ms' }}></span>
            </div>
          </div>
        )}
        
        <div className="flex gap-2">
          {/* Image upload button */}
          <input
            ref={fileInputRef}
            type="file"
            accept="image/*"
            onChange={handleImageUpload}
            className="hidden"
            id="chatbot-image-upload"
          />
          <button
            onClick={() => fileInputRef.current?.click()}
            disabled={isLoading || isAnalyzingImage || isListening}
            className="bg-slate-100 hover:bg-slate-200 disabled:bg-slate-50 text-slate-600 disabled:text-slate-300 p-3 rounded-xl transition-colors flex items-center justify-center"
            title={t.uploadImage}
          >
            <ImagePlus size={20} />
          </button>
          
          {/* Voice input button */}
          {speechSupported && (
            <button
              onClick={toggleVoiceInput}
              disabled={isLoading || isAnalyzingImage}
              className={`p-3 rounded-xl transition-all flex items-center justify-center ${
                isListening 
                  ? 'bg-red-500 hover:bg-red-600 text-white animate-pulse' 
                  : 'bg-slate-100 hover:bg-slate-200 text-slate-600'
              }`}
              title={isListening ? t.voiceListening : t.tapToSpeak}
            >
              {isListening ? <MicOff size={20} /> : <Mic size={20} />}
            </button>
          )}
          
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder={isListening ? t.voiceListening : t.placeholder}
            className={`flex-1 border rounded-xl px-4 py-3 text-sm focus:outline-none focus:ring-2 focus:border-transparent transition-colors ${
              isListening 
                ? 'border-red-300 focus:ring-red-500 bg-red-50' 
                : 'border-slate-200 focus:ring-green-500'
            }`}
            disabled={isLoading || isAnalyzingImage}
          />
          <button
            onClick={() => sendMessage()}
            disabled={!input.trim() || isLoading || isAnalyzingImage}
            className="bg-green-600 hover:bg-green-700 disabled:bg-slate-300 text-white px-4 py-3 rounded-xl transition-colors flex items-center gap-2"
          >
            <Send size={18} />
          </button>
        </div>
      </div>
    </div>
  );
}
